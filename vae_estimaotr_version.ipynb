{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vae_estimaotr_version.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ubermen/anomaly_detector/blob/master/vae_estimaotr_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-Oa9RbaM37gz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is only for when running on Colab:\n",
        "# Get the dependency .py files, if any.\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    # Authenticate the user for better GCS access.\n",
        "    # Copy verification code into the text field to continue.\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sCe76saex-Rb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this code is modified version of tensorflow probability example\n",
        "# https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/vae.py\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import functools\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Dependency imports\n",
        "from absl import flags\n",
        "import argparse\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "tfd = tf.contrib.distributions\n",
        "\n",
        "seq_len = 28\n",
        "enc_size = 128\n",
        "IMAGE_SHAPE = [seq_len, enc_size, 1]\n",
        "\n",
        "flags.DEFINE_float(\"learning_rate\", default=0.0001, help=\"Initial learning rate.\")\n",
        "flags.DEFINE_integer(\"max_steps\", default=1001, help=\"Number of training steps to run.\")\n",
        "flags.DEFINE_integer(\"latent_size\", default=16, help=\"Number of dimensions in the latent code (z).\")\n",
        "flags.DEFINE_integer(\"base_depth\", default=32, help=\"Base depth for layers.\")\n",
        "flags.DEFINE_string(\"activation\", default=\"leaky_relu\", help=\"Activation function for all hidden layers.\")\n",
        "flags.DEFINE_integer(\"batch_size\", default=32, help=\"Batch size.\")\n",
        "flags.DEFINE_integer(\"n_samples\", default=16, help=\"Number of samples to use in encoding.\")\n",
        "flags.DEFINE_integer(\"mixture_components\", default=100,\n",
        "                     help=\"Number of mixture components to use in the prior. Each component is \"\n",
        "                          \"a diagonal normal distribution. The parameters of the components are \"\n",
        "                          \"intialized randomly, and then learned along with the rest of the \"\n",
        "                          \"parameters. If `analytic_kl` is True, `mixture_components` must be \"\n",
        "                          \"set to `1`.\")\n",
        "flags.DEFINE_bool(\"analytic_kl\", default=False,\n",
        "                  help=\"Whether or not to use the analytic version of the KL. When set to \"\n",
        "                       \"False the E_{Z~q(Z|X)}[log p(Z)p(X|Z) - log q(Z|X)] form of the ELBO \"\n",
        "                       \"will be used. Otherwise the -KL(q(Z|X) || p(Z)) + \"\n",
        "                       \"E_{Z~q(Z|X)}[log p(X|Z)] form will be used. If analytic_kl is True, \"\n",
        "                       \"then you must also specify `mixture_components=1`.\")\n",
        "flags.DEFINE_string(\"data_dir\", default=os.path.join(os.getenv(\"TEST_TMPDIR\", \"/tmp\"), \"vae/data\"), help=\"Directory where data is stored (if using real data).\")\n",
        "flags.DEFINE_string(\"model_dir\", default=os.path.join(os.getenv(\"TEST_TMPDIR\", \"/tmp\"), \"vae/\"), help=\"Directory to put the model's fit.\")\n",
        "flags.DEFINE_integer(\"viz_steps\", default=100, help=\"Frequency at which to save visualizations.\")\n",
        "flags.DEFINE_bool(\"fake_data\", default=False, help=\"If true, uses fake data instead of MNIST.\")\n",
        "flags.DEFINE_bool(\"delete_existing\", default=False, help=\"If true, deletes existing `model_dir` directory.\")\n",
        "\n",
        "FLAGS = flags.FLAGS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h1cY5f786QW1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _softplus_inverse(x):\n",
        "  \"\"\"Helper which computes the function inverse of `tf.nn.softplus`.\"\"\"\n",
        "  return tf.log(tf.math.expm1(x))\n",
        "\n",
        "def make_encoder(activation, latent_size, base_depth):\n",
        "  \"\"\"Creates the encoder function.\n",
        "  Args:\n",
        "    activation: Activation function in hidden layers.\n",
        "    latent_size: The dimensionality of the encoding.\n",
        "    base_depth: The lowest depth for a layer.\n",
        "  Returns:\n",
        "    encoder: A `callable` mapping a `Tensor` of images to a\n",
        "      `tfd.Distribution` instance over encodings.\n",
        "  \"\"\"\n",
        "  conv = functools.partial(\n",
        "    tf.keras.layers.Conv2D, padding=\"SAME\", activation=activation)\n",
        "\n",
        "  encoder_net = tf.keras.Sequential([\n",
        "    #conv(base_depth, 5, 1),\n",
        "    conv(base_depth, 5, 2),\n",
        "    #conv(2 * base_depth, 5, 1),\n",
        "    conv(2 * base_depth, 5, 2),\n",
        "    conv(4 * latent_size, (int(seq_len/4), int(enc_size/4)), padding=\"VALID\"),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(2 * latent_size, activation=None),\n",
        "  ])\n",
        "\n",
        "  def encoder(images):\n",
        "    images = 2 * tf.cast(images, dtype=tf.float32) - 1\n",
        "    net = encoder_net(images)\n",
        "\n",
        "    return tfd.MultivariateNormalDiag(\n",
        "      loc=net[..., :latent_size],\n",
        "      scale_diag=tf.nn.softplus(net[..., latent_size:] + _softplus_inverse(1.0)),\n",
        "      name=\"code\")\n",
        "\n",
        "  return encoder\n",
        "\n",
        "def make_decoder(activation, latent_size, output_shape, base_depth):\n",
        "  \"\"\"Creates the decoder function.\n",
        "  Args:\n",
        "    activation: Activation function in hidden layers.\n",
        "    latent_size: Dimensionality of the encoding.\n",
        "    output_shape: The output image shape.\n",
        "    base_depth: Smallest depth for a layer.\n",
        "  Returns:\n",
        "    decoder: A `callable` mapping a `Tensor` of encodings to a\n",
        "      `tfd.Distribution` instance over images.\n",
        "  \"\"\"\n",
        "  deconv = functools.partial(\n",
        "    tf.keras.layers.Conv2DTranspose, padding=\"SAME\", activation=activation)\n",
        "  conv = functools.partial(\n",
        "    tf.keras.layers.Conv2D, padding=\"SAME\", activation=activation)\n",
        "\n",
        "  decoder_net = tf.keras.Sequential([\n",
        "    deconv(2 * base_depth, (int(seq_len/4), int(enc_size/4)), padding=\"VALID\"),\n",
        "    #deconv(2 * base_depth, 5),\n",
        "    deconv(2 * base_depth, 5, 2),\n",
        "    #deconv(base_depth, 5),\n",
        "    deconv(base_depth, 5, 2),\n",
        "    #deconv(base_depth, 5),\n",
        "    conv(output_shape[-1], 5, activation=None),\n",
        "  ])\n",
        "\n",
        "  def decoder(codes):\n",
        "    original_shape = tf.shape(codes)\n",
        "    # Collapse the sample and batch dimension and convert to rank-4 tensor for\n",
        "    # use with a convolutional decoder network.\n",
        "    codes = tf.reshape(codes, (-1, 1, 1, latent_size))\n",
        "    logits = decoder_net(codes)\n",
        "    logits = tf.reshape(logits, shape=tf.concat([original_shape[:-1], output_shape], axis=0))\n",
        "\n",
        "    return tfd.Independent(tfd.Bernoulli(logits=logits),\n",
        "                           reinterpreted_batch_ndims=len(output_shape),\n",
        "                           name=\"image\")\n",
        "\n",
        "  return decoder\n",
        "\n",
        "def make_mixture_prior(latent_size, mixture_components):\n",
        "  \"\"\"Creates the mixture of Gaussians prior distribution.\n",
        "  Args:\n",
        "    latent_size: The dimensionality of the latent representation.\n",
        "    mixture_components: Number of elements of the mixture.\n",
        "  Returns:\n",
        "    random_prior: A `tfd.Distribution` instance representing the distribution\n",
        "      over encodings in the absence of any evidence.\n",
        "  \"\"\"\n",
        "  if mixture_components == 1:\n",
        "    # See the module docstring for why we don't learn the parameters here.\n",
        "    return tfd.MultivariateNormalDiag(\n",
        "      loc=tf.zeros([latent_size]),\n",
        "      scale_identity_multiplier=1.0)\n",
        "\n",
        "  loc = tf.get_variable(name=\"loc\", shape=[mixture_components, latent_size])\n",
        "  raw_scale_diag = tf.get_variable(\n",
        "    name=\"raw_scale_diag\", shape=[mixture_components, latent_size])\n",
        "  mixture_logits = tf.get_variable(\n",
        "    name=\"mixture_logits\", shape=[mixture_components])\n",
        "\n",
        "  return tfd.MixtureSameFamily(\n",
        "    components_distribution=tfd.MultivariateNormalDiag(\n",
        "      loc=loc,\n",
        "      scale_diag=tf.nn.softplus(raw_scale_diag)),\n",
        "    mixture_distribution=tfd.Categorical(logits=mixture_logits),\n",
        "    name=\"prior\")\n",
        "\n",
        "def model_fn(features, labels, mode, params, config):\n",
        "  \"\"\"Builds the model function for use in an estimator.\n",
        "  Arguments:\n",
        "    features: The input features for the estimator.\n",
        "    labels: The labels, unused here.\n",
        "    mode: Signifies whether it is train or test or predict.\n",
        "    params: Some hyperparameters as a dictionary.\n",
        "    config: The RunConfig, unused here.\n",
        "  Returns:\n",
        "    EstimatorSpec: A tf.estimator.EstimatorSpec instance.\n",
        "  \"\"\"\n",
        "  del labels, config\n",
        "\n",
        "  if params[\"analytic_kl\"] and params[\"mixture_components\"] != 1:\n",
        "    raise NotImplementedError(\n",
        "      \"Using `analytic_kl` is only supported when `mixture_components = 1` \"\n",
        "      \"since there's no closed form otherwise.\")\n",
        "\n",
        "  encoder = make_encoder(params[\"activation\"],\n",
        "                         params[\"latent_size\"],\n",
        "                         params[\"base_depth\"])\n",
        "  decoder = make_decoder(params[\"activation\"],\n",
        "                         params[\"latent_size\"],\n",
        "                         IMAGE_SHAPE,\n",
        "                         params[\"base_depth\"])\n",
        "  latent_prior = make_mixture_prior(params[\"latent_size\"],\n",
        "                                    params[\"mixture_components\"])\n",
        "\n",
        "  features_encoded = extract_feature(features)\n",
        "\n",
        "  approx_posterior = encoder(features_encoded)\n",
        "\n",
        "  if mode == tf.estimator.ModeKeys.PREDICT :\n",
        "\n",
        "    approx_posterior_sample = approx_posterior.sample()\n",
        "    decoder_likelihood = decoder(approx_posterior_sample)\n",
        "    distortion = -decoder_likelihood.log_prob(features_encoded)\n",
        "\n",
        "    loss = None\n",
        "    train_op = None\n",
        "    eval_metric_ops = None\n",
        "\n",
        "    prediction = {\n",
        "      '_0' : features,\n",
        "      '_1' : distortion\n",
        "    }\n",
        "\n",
        "    export_outputs = {\n",
        "      'prediction': tf.estimator.export.PredictOutput(prediction)\n",
        "    }\n",
        "\n",
        "  else :\n",
        "\n",
        "    approx_posterior_sample = approx_posterior.sample(params[\"n_samples\"])\n",
        "\n",
        "    decoder_likelihood = decoder(approx_posterior_sample)\n",
        "\n",
        "    # `distortion` is just the negative log likelihood.\n",
        "    distortion = -decoder_likelihood.log_prob(features_encoded)\n",
        "    avg_distortion = tf.reduce_mean(distortion)\n",
        "    tf.summary.scalar(\"distortion\", avg_distortion)\n",
        "\n",
        "    if params[\"analytic_kl\"]:\n",
        "      rate = tfd.kl_divergence(approx_posterior, latent_prior)\n",
        "    else:\n",
        "      rate = (approx_posterior.log_prob(approx_posterior_sample)\n",
        "              - latent_prior.log_prob(approx_posterior_sample))\n",
        "    avg_rate = tf.reduce_mean(rate)\n",
        "    tf.summary.scalar(\"rate\", avg_rate)\n",
        "\n",
        "    elbo_local = -(rate + distortion)\n",
        "\n",
        "    elbo = tf.reduce_mean(elbo_local)\n",
        "\n",
        "    tf.summary.scalar(\"elbo\", elbo)\n",
        "\n",
        "    importance_weighted_elbo = tf.reduce_mean(\n",
        "      tf.reduce_logsumexp(elbo_local, axis=0) -\n",
        "      tf.log(tf.to_float(params[\"n_samples\"])))\n",
        "    tf.summary.scalar(\"elbo/importance_weighted\", importance_weighted_elbo)\n",
        "\n",
        "    # Decode samples from the prior for visualization.\n",
        "    random_image = decoder(latent_prior.sample(16))\n",
        "\n",
        "    # Perform variational inference by minimizing the -ELBO.\n",
        "    global_step = tf.train.get_or_create_global_step()\n",
        "    learning_rate = tf.train.cosine_decay(params[\"learning_rate\"], global_step,\n",
        "                                          params[\"max_steps\"])\n",
        "    tf.summary.scalar(\"learning_rate\", learning_rate)\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "    loss = -elbo\n",
        "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
        "    eval_metric_ops={\n",
        "      \"elbo\": tf.metrics.mean(elbo),\n",
        "      \"elbo/importance_weighted\": tf.metrics.mean(importance_weighted_elbo),\n",
        "      \"rate\": tf.metrics.mean(avg_rate),\n",
        "      \"distortion\": tf.metrics.mean(avg_distortion),\n",
        "    }\n",
        "\n",
        "    prediction = None\n",
        "    export_outputs = None\n",
        "\n",
        "  return tf.estimator.EstimatorSpec(\n",
        "    mode=mode,\n",
        "    loss=loss,\n",
        "    train_op=train_op,\n",
        "    eval_metric_ops=eval_metric_ops,\n",
        "    predictions=prediction,\n",
        "    export_outputs=export_outputs,\n",
        "  )\n",
        "\n",
        "def static_nlog_dataset(data_dir, file_name):\n",
        "  dataset = tf.data.TextLineDataset(data_dir + '/' + file_name)\n",
        "  return dataset\n",
        "\n",
        "def build_input_fns(data_dir, batch_size):\n",
        "  \"\"\"Builds an Iterator switching between train and heldout data.\"\"\"\n",
        "\n",
        "  # Build an iterator over training batches.\n",
        "  training_dataset = static_nlog_dataset(data_dir, 'globalsignin_devicemodel_train')\n",
        "  training_dataset = training_dataset.shuffle(1000).repeat().batch(batch_size)\n",
        "  train_input_fn = lambda: training_dataset.make_one_shot_iterator().get_next()\n",
        "\n",
        "  # Build an iterator over the heldout set.\n",
        "  eval_dataset = static_nlog_dataset(data_dir, 'globalsignin_devicemodel_eval')\n",
        "  eval_dataset = eval_dataset.batch(batch_size)\n",
        "  eval_input_fn = lambda: eval_dataset.make_one_shot_iterator().get_next()\n",
        "\n",
        "  return train_input_fn, eval_input_fn\n",
        "\n",
        "def _get_session_config_from_env_var():\n",
        "  \"\"\"Returns a tf.ConfigProto instance that has appropriate device_filters set.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  tf_config = json.loads(os.environ.get('TF_CONFIG', '{}'))\n",
        "\n",
        "  if (tf_config and 'task' in tf_config and 'type' in tf_config['task'] and\n",
        "          'index' in tf_config['task']):\n",
        "    # Master should only communicate with itself and ps\n",
        "    if tf_config['task']['type'] == 'master':\n",
        "      return tf.ConfigProto(device_filters=['/job:ps', '/job:master'])\n",
        "    # Worker should only communicate with itself and ps\n",
        "    elif tf_config['task']['type'] == 'worker':\n",
        "      return tf.ConfigProto(device_filters=[\n",
        "        '/job:ps',\n",
        "        '/job:worker/task:%d' % tf_config['task']['index']\n",
        "      ])\n",
        "  return None\n",
        "\n",
        "def serving_input_fn():\n",
        "  string_array = tf.placeholder(tf.string, [None])\n",
        "  return tf.estimator.export.TensorServingInputReceiver(string_array, string_array)\n",
        "\n",
        "def extract_feature(string_array):\n",
        "  string_array = tf.strings.substr(string_array,0,seq_len)\n",
        "  split_stensor = tf.string_split(string_array, delimiter=\"\")\n",
        "  split_values = split_stensor.values\n",
        "  unicode_values = tf.map_fn(lambda x: tf.io.decode_raw(x, tf.uint8)[0], split_values, dtype=tf.uint8)\n",
        "  unicode_values = tf.map_fn(lambda x: tf.cond(tf.math.less(x, enc_size), lambda: x, lambda: tf.constant(32, dtype=tf.uint8)), unicode_values)\n",
        "  unicode_tensor = tf.sparse_to_dense(split_stensor.indices, [tf.shape(string_array)[0], seq_len], unicode_values, default_value=-1)\n",
        "  encoded_tensor = tf.map_fn(lambda x: tf.one_hot(x, enc_size), unicode_tensor, dtype=tf.float32)\n",
        "  reshaped_tensor = tf.map_fn(lambda x: tf.reshape(x, IMAGE_SHAPE), encoded_tensor)\n",
        "  return reshaped_tensor\n",
        "\n",
        "def main(argv):\n",
        "  del argv  # unused\n",
        "\n",
        "  params = FLAGS.flag_values_dict()\n",
        "  params[\"activation\"] = getattr(tf.nn, params[\"activation\"])\n",
        "  if FLAGS.delete_existing and tf.gfile.Exists(FLAGS.model_dir):\n",
        "    tf.logging.warn(\"Deleting old log directory at {}\".format(FLAGS.model_dir))\n",
        "    tf.gfile.DeleteRecursively(FLAGS.model_dir)\n",
        "  tf.gfile.MakeDirs(FLAGS.model_dir)\n",
        "\n",
        "  train_input_fn, eval_input_fn = build_input_fns(FLAGS.data_dir, FLAGS.batch_size)\n",
        "\n",
        "  train_spec = tf.estimator.TrainSpec(\n",
        "    train_input_fn, max_steps=FLAGS.max_steps)\n",
        "\n",
        "  exporter = tf.estimator.FinalExporter('exporter', serving_input_fn)\n",
        "\n",
        "  eval_spec = tf.estimator.EvalSpec(\n",
        "    eval_input_fn,\n",
        "    steps=FLAGS.viz_steps,\n",
        "    exporters=[exporter],\n",
        "    name='lqad-eval')\n",
        "\n",
        "  run_config = tf.estimator.RunConfig(session_config=_get_session_config_from_env_var())\n",
        "  run_config = run_config.replace(model_dir=FLAGS.model_dir)\n",
        "\n",
        "  estimator = tf.estimator.Estimator(\n",
        "    model_fn,\n",
        "    params=params,\n",
        "    config=run_config\n",
        "  )\n",
        "\n",
        "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lGwqxTG3o3md",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  FLAGS.data_dir = \"gs://bigus/data\"\n",
        "  FLAGS.model_dir = \"gs://bigus/colab_test_66\"\n",
        "  FLAGS.max_steps = 101\n",
        "  tf.app.run()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}